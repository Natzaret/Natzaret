{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URV                                                                            MESIIA\n",
    "\n",
    "Neural and Evolutionary Computation (NEC)\n",
    "Assignment 3: Unsupervised learning with PCA, t-SNE, k-means, AHC and SOM\n",
    "\n",
    "Teachers: Dr. Jordi Duch, Dr. Sergio Gomez\n",
    "\n",
    "Student: Natzaret Gálvez Rísquez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Selecting and analyzing the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unsupervised learning techniques must be applied on two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We upload the datasets\n",
    "\n",
    "# First dataset: File: A3-data.txt\n",
    "    # Features: 4 variables, 1 class\n",
    "    # Patterns: 360 patterns\n",
    "df_data=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A3/A3-data.txt', sep=',', header=None)\n",
    "header_vector_data = df_data.iloc[0, :].tolist() #header\n",
    "df_data=df_data.iloc[1:,:-1]\n",
    "df_data=pd.DataFrame(df_data)\n",
    "\n",
    "# Second dataset: from \"https://www.openml.org/search?type=data&status=active&id=188\"\n",
    "    # Features: at least 6 variables, and a class attribute\n",
    "    # The class attribute must refer to, at least, 4 different classes\n",
    "    #  Patterns: at least 200 patterns\n",
    "data_Eucaliptus, meta = arff.loadarff('C:/Users/Gari/Desktop/Assignments_NEC/A3/dataset_194_eucalyptus.arff')\n",
    "# Convert numpy array to DataFrame\n",
    "# [736 rows x 20 columns], number of classes 5\n",
    "df_Eucaliptus = pd.DataFrame(data_Eucaliptus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta) # Details of the second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_Eucaliptus) # Details of the second dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Comparing unsupervised learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform unsupervised learning of the two datasets using the following algorithms:\n",
    "PCA, t-SNE, k-means, AHC and SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def apply_pca(data, n_components=2, labels):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(data)\n",
    "\n",
    "    # Scatter plot of the first two principal components\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(pca_result[:, 0], pca_result[:, 1], c=labels, cmap='viridis')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title('PCA Projection')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # Scree plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o', linestyle='-')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.title('Scree Plot')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def apply_tsne(data, perplexity=30, labels):\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity)\n",
    "    tsne_result = tsne.fit_transform(data)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=labels, cmap='viridis')\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    plt.title(f't-SNE Projection (Perplexity={perplexity})')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def apply_kmeans(data, k, labels):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(data)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # Scatter plot of the data colored according to the classes they belong to\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title('True Classes')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # Scatter plot of the data colored according to the clusters obtained by K-means\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=cluster_labels, cmap='viridis')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(f'K-means Clustering (k={k})')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # Compare with the real class labels\n",
    "    if k == len(np.unique(labels)):\n",
    "        cm = confusion_matrix(labels, cluster_labels)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHC\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Method UPGMA -> method average\n",
    "def apply_ahc(data, labels, method='average'):\n",
    "    # Calculate Euclidean distances between original patterns\n",
    "    distances = pdist(data)\n",
    "\n",
    "    # Calculate linkage matrix\n",
    "    linkage_matrix = linkage(distances, method=method)\n",
    "\n",
    "    # Plot dendrogram with colors representing original classes\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    dendrogram(linkage_matrix, \n",
    "               color_threshold=0, \n",
    "               labels=labels,\n",
    "               leaf_font_size=10,\n",
    "               above_threshold_color='k')\n",
    "    plt.title(f'Agglomerative Hierarchical Clustering ({method.capitalize()} Linkage)')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOM\n",
    "from sompy.sompy import SOMFactory\n",
    "\n",
    "def apply_som(data, mapsize=(10, 10), topology='rectangular', learning_rate=0.02, neighborhood_function='gaussian', labels):\n",
    "    # Ensure at least 100 neurons\n",
    "    if mapsize[0] * mapsize[1] < 100:\n",
    "        raise ValueError(\"Number of neurons is less than 100. Please choose a larger mapsize.\")\n",
    "\n",
    "    som = SOMFactory.build(data, mapsize=mapsize, topology=topology, normalization='var', initialization='pca')\n",
    "    som.train(n_job=1, verbose=False, train_rough_len=20, train_finetune_len=100, learning_rate=learning_rate,\n",
    "              neighborhood=neighborhood_function)\n",
    "\n",
    "    # Plot component planes\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    som.component_planes()\n",
    "    plt.suptitle('Component Planes')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot U-matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    som.view_umatrix(bestmatches=True, colormap='viridis', colorbar=True)\n",
    "    plt.title('U-matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot heatmap of the most represented class in each position\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    som.plot_heatmap()\n",
    "    plt.title('Heatmap of the Most Represented Class')\n",
    "    plt.show()\n",
    "\n",
    "    # Find the best matching units (BMUs) for each data point\n",
    "    bmus = som.find_bmu(data)\n",
    "    \n",
    "    # Calculate the most represented class for each position\n",
    "    unique_classes = np.unique(labels)\n",
    "    most_represented_class = np.zeros(som.codebook.mapsize)\n",
    "    for i, j in np.ndindex(som.codebook.mapsize):\n",
    "        most_represented_class[i, j] = np.argmax(np.bincount(labels[bmus == (i, j)]))\n",
    "\n",
    "    # Plot heatmap of the most represented class in each position\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(most_represented_class, cmap='viridis')\n",
    "    plt.colorbar(label='Class')\n",
    "    plt.title('Heatmap of the Most Represented Class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 1: data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =\n",
    "\n",
    "apply_pca(df_data, labels)\n",
    "apply_tsne(df_data, labels)\n",
    "apply_kmeans(df_data, k=1, labels)\n",
    "apply_ahc(df_data)\n",
    "apply_som(df_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 2: eucaliptus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =\n",
    "\n",
    "apply_pca(df_Eucaliptus, labels)\n",
    "apply_tsne(df_Eucaliptus, labels)\n",
    "apply_kmeans(df_Eucaliptus, k=5, labels)\n",
    "apply_ahc(df_Eucaliptus)\n",
    "apply_som(df_Eucaliptus, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
