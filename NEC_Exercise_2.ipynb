{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URV                                                                            MESIIA\n",
    "\n",
    "Neural and Evolutionary Computation (NEC)\n",
    "\n",
    "Assignment 2: Classification with SVM, BP and MLR\n",
    "\n",
    "Teachers: Dr. Jordi Duch, Dr. Sergio Gomez\n",
    "\n",
    "Student: Natzaret Gálvez Rísquez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Selecting and analyzing the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform the classification in the following three datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We upload the datasets\n",
    "\n",
    "# First dataset: File: A2-ring.txt\n",
    "    # Training set 1 : ring-separable.txt\n",
    "    # Training set 2 : ring-merged.txt\n",
    "    # Two different training sets, one easy (separable) and one more difficult (merged)\n",
    "\n",
    "    # Test (valid for set1 and set2): ring-test.txt (Only one test set for both training sets)\n",
    "    # 2 input features + 1 class identifier (0 / 1)\n",
    "    # All data files have 10000 patterns\n",
    "    \n",
    "A2_ring_merged=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-ring/A2-ring-merged.txt', sep='\\t', header=None)\n",
    "A2_ring_separable=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-ring/A2-ring-separable.txt', sep='\\t', header=None)\n",
    "A2_ring_test=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-ring/A2-ring-test.txt', sep='\\t', header=None)\n",
    "\n",
    "df_A2_ring_merged=pd.DataFrame(A2_ring_merged)\n",
    "df_A2_ring_separable=pd.DataFrame(A2_ring_separable)\n",
    "df_A2_ring_test=pd.DataFrame(A2_ring_test)\n",
    "\n",
    "# We plot the two input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second dataset: File: A2-bank.txt\n",
    "    # Data: bank-additional.csv (4119 patterns) or bank-additional-full.csv (41188 patterns), we choose one of them (the first is a subset of the second)\n",
    "    # Training: select the first 80% patterns for training\n",
    "    # Test: select the last 20% patterns for test\n",
    "    # Features: 20 features, most of them categorical, you will have to properly represent them as numerical data before training\n",
    "    # Input features: features that refer to the bank client, last contact in the current campaign, other attributes, and social and economic context attributes\n",
    "    # Prediction feature: the last one (yes/no), which corresponds to whether the client has subscribed a term deposit or not\n",
    "    # Observation: missing information is tagged as “unknown”\n",
    "\n",
    "bank_additional=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-bank/bank-additional.csv', sep=';', header=None)\n",
    "#bank_additional_full=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-bank/bank-additional-full.csv', sep=';', header=None)\n",
    "#bank_additional_names= pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-bank/bank-additional-names.txt', sep=\"\\t\", header=None)\n",
    "\n",
    "df_bank_additional=pd.DataFrame(bank_additional)\n",
    "#df_bank_additional_full=pd.DataFrame(bank_additional_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third dataset: from \"https://www.kaggle.com/datasets/fatemehmehrparvar/liver-disorders?resource=download\"\n",
    "    # At least 6 features, one of them used for classification\n",
    "    # he classification feature can be binary or multivariate\n",
    "    # At least 400 patterns\n",
    "    # Select randomly 80% of the patterns for training and validation, and the remaining 20% for test; it is important to shuffle the original data, to destroy any kind of sorting it could have\n",
    "\n",
    "# Indian liver patient dataset [584 rows x 11 columns]\n",
    "liver_Disorder=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/Indian Liver Patient Dataset (ILPD).csv', sep=',', header=None)\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "df_liver_Disorder=pd.DataFrame(liver_Disorder)\n",
    "\n",
    "#We drop the header\n",
    "# Drop the first row\n",
    "df_liver_Disorder = df_liver_Disorder.drop(df_liver_Disorder.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will do the data preprocessing to later do the data splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values, we check for and handle any missing values in our datasets\n",
    "# Categorical values, if there are categorical variables, we encode them appropriately\n",
    "# Outliers, we identify and handle the outliers in the data\n",
    "# Normalization, in case is needed\n",
    "\n",
    "# Data Preprocessing for Dataset 1 and 2\n",
    "# - Normalize input and output variables\n",
    "# - No need to preprocess (datasets already cleaned)\n",
    "\n",
    "# Data Preprocessing for Dataset 3\n",
    "# - Link to the source webpage to the documentation: \"\"https://www.kaggle.com/datasets/fatemehmehrparvar/liver-disorders?resource=download\"\n",
    "# - Check for missing values, represent categorical values, look for outliers\n",
    "# - Normalize input/output variables if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-ring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2-ring\n",
    "# We normalize the data that has been already splitted\n",
    "X_A2_ring_separable = df_A2_ring_separable.iloc[:, :-1]  # Features separable (all columns except the last one)\n",
    "y_A2_ring_separable = df_A2_ring_separable.iloc[:, -1]  # Target variable\n",
    "\n",
    "X_A2_ring_merged = df_A2_ring_merged.iloc[:, :-1]  # Features merged\n",
    "y_A2_ring_merged = df_A2_ring_merged.iloc[:, -1]  # Target variable\n",
    "\n",
    "X_A2_ring_test = df_A2_ring_test.iloc[:, :-1]  # Features\n",
    "y_A2_ring_test = df_A2_ring_test.iloc[:, -1]  # Target variable\n",
    "\n",
    "scaler_ring = MinMaxScaler()\n",
    "X_train_ring_separable = scaler_ring.fit_transform(X_A2_ring_separable) # Training set 1\n",
    "# Reshape the array to a 2D shape (required by MinMaxScaler)\n",
    "y_train_ring_separable = scaler_ring.fit_transform(y_A2_ring_separable.values.reshape(-1, 1))\n",
    "\n",
    "X_train_ring_merged = scaler_ring.fit_transform(X_A2_ring_merged) # Trainig set 2\n",
    "y_train_ring_merged = scaler_ring.fit_transform(y_A2_ring_merged.values.reshape(-1, 1))\n",
    "\n",
    "X_test_ring_normalized = scaler_ring.fit_transform(X_A2_ring_test) # Test\n",
    "y_test_ring_normalized = scaler_ring.fit_transform(y_A2_ring_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-bank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2-bank\n",
    "\n",
    "# Before normalizing the second dataset, it needs to be treated.\n",
    "# We have to treat the categorical data and the \"unknown\" values.\n",
    "\n",
    "# Treatment of the categorical data and the \"unknown\" values\n",
    "# Replace \"unknown\" values with NaN\n",
    "df_bank_additional.replace(\"unknown\", np.nan, inplace=True)\n",
    "\n",
    "# Handling missing values\n",
    "df_bank_additional.fillna(df_bank_additional.mode().iloc[0], inplace=True)\n",
    "\n",
    "# Extract the column names from the first row\n",
    "df_bank_additional.columns = df_bank_additional.iloc[0]\n",
    "df_bank_additional = df_bank_additional[1:]\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = df_bank_additional.select_dtypes(include=\"object\").columns\n",
    "\n",
    "for column in categorical_columns:\n",
    "    df_bank_additional[column] = label_encoder.fit_transform(df_bank_additional[column])\n",
    "\n",
    "# Separate the target variable\n",
    "X_bank_additional = df_bank_additional.drop(\"y\", axis=1)  # Features\n",
    "y_bank_additional = df_bank_additional[\"y\"]  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2-bank\n",
    "# Now, we normalize the data\n",
    "scaler_bank = MinMaxScaler()\n",
    "X_train_bank_additional = scaler_bank.fit_transform(X_bank_additional) # bank additional\n",
    "# Reshape the array to a 2D shape (required by MinMaxScaler)\n",
    "y_train_bank_additional = scaler_bank.fit_transform(y_bank_additional.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2-bank\n",
    "# Split the data into validation-training and testing sets\n",
    "# Extract the first 80% for training\n",
    "# Extract the remaining 20% for testing\n",
    "# Splitting A2-bank dataset\n",
    "X_train_bank, X_test_bank, y_train_bank, y_test_bank = train_test_split(\n",
    "    X_train_bank_additional, y_train_bank_additional, test_size=0.20, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liver disorder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Liver disorder dataset: 4\n"
     ]
    }
   ],
   "source": [
    "# Liver disorder\n",
    "# We check if this dataset have missing values:\n",
    "missing_values_count = df_liver_Disorder.isnull().sum().sum()\n",
    "print(f\"Number of missing values in Liver disorder dataset: {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert the categorical data into numerical\n",
    "# Observing the dataset, there is a column with categorical data, which is the \"Gender\" with the name 1\n",
    "gender_mapping = {'Female': 0, 'Male': 1}\n",
    "df_liver_Disorder[1] = df_liver_Disorder[1].replace(gender_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We handle missing values using median imputation\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_liver_Disorder_imputed = pd.DataFrame(imputer.fit_transform(df_liver_Disorder), columns=df_liver_Disorder.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Liver disorder dataset: 0\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = df_liver_Disorder_imputed.isnull().sum().sum()\n",
    "print(f\"Number of missing values in Liver disorder dataset: {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and handle outliers using IQR method\n",
    "def handle_outliers_iqr(data, threshold=1.5):\n",
    "    data_copy = data.copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "    Q1 = data_copy.quantile(0.25)\n",
    "    Q3 = data_copy.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "    data_copy[(data_copy < lower_bound) | (data_copy > upper_bound)] = np.nan\n",
    "\n",
    "    # Handle missing values using median imputation\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    data_imputed = imputer.fit_transform(data_copy)\n",
    "    \n",
    "    # Convert back to DataFrame with original column names\n",
    "    data_imputed = pd.DataFrame(data_imputed, columns=data.columns)\n",
    "\n",
    "    return data_imputed\n",
    "\n",
    "# Handle outliers in all feature variables (columns) of df_liver_Disorder\n",
    "df_liver_Disorder_no_outliers = handle_outliers_iqr(df_liver_Disorder_imputed)\n",
    "\n",
    "# Shuffle\n",
    "df_liver_Disorder_shuffled = df_liver_Disorder_no_outliers.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Liver disorder dataset: 0\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = df_liver_Disorder_shuffled.isnull().sum().sum()\n",
    "print(f\"Number of missing values in Liver disorder dataset: {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_liver_Disorder = df_liver_Disorder_shuffled.iloc[:, :-1]\n",
    "y_liver_Disorder = df_liver_Disorder_shuffled.iloc[:, -1]\n",
    "\n",
    "# Normalize input variables\n",
    "scaler_liver_Disorder = MinMaxScaler()\n",
    "X_liver_Disorder_normalized_no_outliers = scaler_liver_Disorder.fit_transform(X_liver_Disorder)\n",
    "y_liver_Disorder_normalized_no_outliers = scaler_liver_Disorder.fit_transform(y_liver_Disorder.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third dataset, Liver disorder\n",
    "# Split the data into validation-training and testing sets\n",
    "# Extract the first 80% for training\n",
    "# Extract the remaining 20% for testing\n",
    "# Splitting liver_Disorder dataset\n",
    "X_train_wineQuality, X_test_wineQuality, y_train_wineQuality, y_test_wineQuality = train_test_split(\n",
    "    X_liver_Disorder_normalized_no_outliers,\n",
    "    y_liver_Disorder_normalized_no_outliers,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform supervised training of 3 classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM (support vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of SVM: kernel, and parameters\n",
    "def evaluate_svm(X_train, y_train, X_test, y_test, kernel, C):\n",
    "    # Create an SVM classifier with the desired parameters\n",
    "    svm_classifier = SVC(kernel=kernel, C=C)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(svm_classifier, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "    expected_error = 1 - np.mean(cv_scores)  # Expected classification error\n",
    "    \n",
    "    # Train the SVM classifier on the entire training set\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the classification error on the test set\n",
    "    test_error = 1 - accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return expected_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BP (back propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of BP: architecture of the network, learning rate and momentum, activation function, and number of epochs\n",
    "\n",
    "def evaluate_bp(X_train, y_train, X_test, y_test, learning_rate, momentum, activation, epochs):\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    # Define the neural network model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(32, activation=activation),\n",
    "        tf.keras.layers.Dense(10, activation=activation),\n",
    "        tf.keras.layers.Dense(5, activation=activation),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # Define the optimizer with custom learning rate and momentum\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    expected_error = 1 - np.mean(cv_scores)  # Expected classification error\n",
    "    \n",
    "    # Fit the model to the entire training set\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the classification error on the test set\n",
    "    test_error = 1 - accuracy_score(y_test, y_pred.round())\n",
    "    \n",
    "    return expected_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLR (multi-linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mlr(X_train, y_train, X_test, y_test, C, solver):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    # Create a logistic regression classifier with the current parameters\n",
    "    logistic_regression = LogisticRegression(C, solver)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(logistic_regression, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "    expected_error = 1 - np.mean(cv_scores)  # Expected classification error\n",
    "    \n",
    "    # Train the logistic regression classifier on the entire training set\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = logistic_regression.predict(X_test)\n",
    "    \n",
    "    # Calculate the classification error on the test set\n",
    "    test_error = 1 - accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return expected_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic process to find the best parameters (kernel, C) for the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_svm(X_train, y_train, X_test, y_test):\n",
    "    # Set initial parameters\n",
    "    C_values = [0.1, 1, 10, 100, 1000]  # Values for C\n",
    "    kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']  # Values for kernel\n",
    "    best_error = float('inf')\n",
    "    best_params = {'kernel': None, 'C': None}\n",
    "\n",
    "    # Tune C\n",
    "    for C in C_values:\n",
    "        # Calculate the classification error\n",
    "        expected_error, test_error = evaluate_svm(X_train, y_train, X_test, y_test, kernel=kernel_values[0], C=C)\n",
    "        \n",
    "        # Update best error and parameters if current error is lower\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_params['C'] = C\n",
    "        \n",
    "    # Tune kernel\n",
    "    for kernel in kernel_values:\n",
    "        expected_error, test_error = evaluate_svm(X_train, y_train, X_test, y_test, kernel=kernel_values[0], C=C)\n",
    "        \n",
    "        # Update best error and parameters if current error is lower\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_params['kernel'] = kernel\n",
    "    \n",
    "    return best_params, best_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic process to find the best parameters (learning_rate, momentum, activation, epochs) for the BP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_backpropagation(X_train, y_train, X_test, y_test):\n",
    "    # Set initial parameters\n",
    "    learning_rates = [0.2, 0.15, 0.1, 0.015, 0.01]  # Values for learning rate\n",
    "    momentums = [0.0, 0.3, 0.6, 0.9]  # Values for momentum\n",
    "    activations = ['sigmoid', 'relu', 'linear', 'tanh']  # Values for activation\n",
    "    epochs_values = [50, 100, 200, 500, 1000] # Number of epochs\n",
    "\n",
    "    best_error  = float('inf')  # Initialize with a large value\n",
    "    best_hyperparameters = {'learning_rate': None, 'momentum': None, 'activation': None, 'epochs': None}\n",
    "\n",
    " # Tune learning rate\n",
    "    for learning_rate in learning_rates:\n",
    "        test_error = evaluate_bp(X_train, y_train, X_test, y_test, learning_rate, momentums[0], activations[0], epochs_values[0])\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_hyperparameters['learning_rate'] = learning_rate\n",
    "\n",
    "    # Tune momentum\n",
    "    for momentum in momentums:\n",
    "        test_error = evaluate_bp(X_train, y_train, X_test, y_test, best_hyperparameters['learning_rate'], momentum, activations[0], epochs_values[0])\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_hyperparameters['momentum'] = momentum\n",
    "\n",
    "    # Tune activation\n",
    "    for activation in activations:\n",
    "        test_error = evaluate_bp(X_train, y_train, X_test, y_test, best_hyperparameters['learning_rate'], best_hyperparameters['momentum'], activations, epochs_values[0])\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_hyperparameters['activation'] = activation\n",
    "\n",
    "    # Tune epochs\n",
    "    for epochs in epochs_values:\n",
    "        test_error = evaluate_bp(X_train, y_train, X_test, y_test, best_hyperparameters['learning_rate'], best_hyperparameters['momentum'], best_hyperparameters['activation'], epochs_values)\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_hyperparameters['epochs'] = epochs\n",
    "\n",
    "    return best_hyperparameters, best_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic process to find the best parameters (C, solver) for the MLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    # Set initial parameters\n",
    "    C_values = [0.01, 0.1, 1, 10, 100]  # Values for regularization parameter C\n",
    "    solver_values = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']  # Values for the optimization algorithm\n",
    "\n",
    "    best_error = float('inf')  # Initialize with a large value\n",
    "    best_params = {'C': None, 'solver': None}\n",
    "\n",
    "# Tune C\n",
    "    for C in C_values:\n",
    "        # Create a logistic regression classifier with the current C value\n",
    "        logistic_regression = LogisticRegression(C=C, solver=solver_values[1])\n",
    "\n",
    "        # Train the logistic regression classifier\n",
    "        logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "        # Calculate the classification error on the test set\n",
    "        test_error = 1 - accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Update best error and C if current error is lower\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_params['C'] = C\n",
    "\n",
    "    # Tune solver\n",
    "    for solver in solver_values:\n",
    "        # Create a logistic regression classifier with the current solver\n",
    "        logistic_regression = LogisticRegression(C=best_params['C'], solver=solver)\n",
    "\n",
    "        # Train the logistic regression classifier\n",
    "        logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "        # Calculate the classification error on the test set\n",
    "        test_error = 1 - accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Update best error and solver if current error is lower\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_params['solver'] = solver\n",
    "\n",
    "    return best_params, best_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the before functions to finde the best parameters for our datasets for the three models (SVM, BP, MLR):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 1: A2-ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'kernel': 'rbf', 'C': 0.1}\n",
      "Best classification error for SVM: 0.04300000000000004\n",
      "WARNING:tensorflow:From c:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.src.engine.sequential.Sequential object at 0x00000128DAC59410>' (type <class 'keras.src.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC_Exercise_2.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest classification error for SVM:\u001b[39m\u001b[39m\"\u001b[39m, best_error_svm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# BP\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m best_params_bp, best_error_bp \u001b[39m=\u001b[39m tune_backpropagation(X_train, y_train, X_test, y_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest parameters for BP:\u001b[39m\u001b[39m\"\u001b[39m, best_params_bp)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest classification error for BP:\u001b[39m\u001b[39m\"\u001b[39m, best_error_bp)\n",
      "\u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC_Exercise_2.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Tune learning rate\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m    \u001b[39mfor\u001b[39;00m learning_rate \u001b[39min\u001b[39;00m learning_rates:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m        test_error \u001b[39m=\u001b[39m evaluate_bp(X_train, y_train, X_test, y_test, learning_rate, momentums[\u001b[39m0\u001b[39;49m], activations[\u001b[39m0\u001b[39;49m], epochs_values[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m        \u001b[39mif\u001b[39;00m test_error \u001b[39m<\u001b[39m best_error:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m            best_error \u001b[39m=\u001b[39m test_error\n",
      "\u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC_Exercise_2.ipynb Cell 41\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Perform cross-validation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m cv_scores \u001b[39m=\u001b[39m cross_val_score(model, X_train, y_train, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m expected_error \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(cv_scores)  \u001b[39m# Expected classification error\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Gari/Desktop/NEC_Exercise_2.ipynb#X55sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Fit the model to the entire training set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1786\u001b[0m \u001b[39myield\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[39m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[1;32m-> 1789\u001b[0m \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m iterable:\n\u001b[0;32m   1790\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_dispatched_batches \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n\u001b[0;32m   1791\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_dispatched_tasks \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\sklearn\\utils\\parallel.py:61\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m---> 61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;49;00m delayed_func, args, kwargs \u001b[39min\u001b[39;49;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:311\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m--> 311\u001b[0m         clone(estimator),\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\sklearn\\base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39m__sklearn_clone__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m inspect\u001b[39m.\u001b[39misclass(estimator):\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39m__sklearn_clone__()\n\u001b[1;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[39m=\u001b[39;49msafe)\n",
      "File \u001b[1;32mc:\\Users\\Gari\\Desktop\\NEC\\projects\\Lib\\site-packages\\sklearn\\base.py:98\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     93\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m             )\n\u001b[0;32m     97\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[0;32m    103\u001b[0m             )\n\u001b[0;32m    105\u001b[0m klass \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\n\u001b[0;32m    106\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<keras.src.engine.sequential.Sequential object at 0x00000128DAC59410>' (type <class 'keras.src.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "X_train = X_train_ring_merged\n",
    "y_train = y_train_ring_merged\n",
    "X_test = X_test_ring_normalized\n",
    "y_test = y_test_ring_normalized\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#SVM\n",
    "best_params_svm, best_error_svm = tune_svm(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for SVM:\", best_params_svm)\n",
    "print(\"Best classification error for SVM:\", best_error_svm)\n",
    "\n",
    "# BP\n",
    "best_params_bp, best_error_bp = tune_backpropagation(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for BP:\", best_params_bp)\n",
    "print(\"Best classification error for BP:\", best_error_bp)\n",
    "\n",
    "#MLR\n",
    "best_params_mlr, best_error_mlr = tune_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for MLR:\", best_params_mlr)\n",
    "print(\"Best classification error for MLR:\", best_error_mlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 2: A2-bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_bank\n",
    "y_train = y_train_bank\n",
    "X_test = X_test_bank\n",
    "y_test = y_test_bank\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#SVM\n",
    "best_params_svm, best_error_svm = tune_svm(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for SVM:\", best_params_svm)\n",
    "print(\"Best classification error for SVM:\", best_error_svm)\n",
    "\n",
    "# BP\n",
    "best_params_bp, best_error_bp = tune_backpropagation(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for BP:\", best_params_bp)\n",
    "print(\"Best classification error for BP:\", best_error_bp)\n",
    "\n",
    "#MLR\n",
    "best_params_mlr, best_error_mlr = tune_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for MLR:\", best_params_mlr)\n",
    "print(\"Best classification error for MLR:\", best_error_mlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 3: liver disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_wineQuality\n",
    "y_train = y_train_wineQuality\n",
    "X_test = X_test_wineQuality\n",
    "y_test = y_test_wineQuality\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#SVM\n",
    "best_params_svm, best_error_svm = tune_svm(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for SVM:\", best_params_svm)\n",
    "print(\"Best classification error for SVM:\", best_error_svm)\n",
    "\n",
    "# BP\n",
    "best_params_bp, best_error_bp = tune_backpropagation(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for BP:\", best_params_bp)\n",
    "print(\"Best classification error for BP:\", best_error_bp)\n",
    "\n",
    "#MLR\n",
    "best_params_mlr, best_error_mlr = tune_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for MLR:\", best_params_mlr)\n",
    "print(\"Best classification error for MLR:\", best_error_mlr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
