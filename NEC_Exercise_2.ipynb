{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import warnings\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URV                                                                            MESIIA\n",
    "\n",
    "Neural and Evolutionary Computation (NEC)\n",
    "\n",
    "Assignment 2: Classification with SVM, BP and MLR\n",
    "\n",
    "Teachers: Dr. Jordi Duch, Dr. Sergio Gomez\n",
    "\n",
    "Student: Natzaret Gálvez Rísquez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Selecting and analyzing the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform the classification in the following three datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We upload the datasets\n",
    "\n",
    "# First dataset: File: A2-ring.txt\n",
    "    # Training set 1 : ring-separable.txt\n",
    "    # Training set 2 : ring-merged.txt\n",
    "    # Two different training sets, one easy (separable) and one more difficult (merged)\n",
    "\n",
    "    # Test (valid for set1 and set2): ring-test.txt (Only one test set for both training sets)\n",
    "    # 2 input features + 1 class identifier (0 / 1)\n",
    "    # All data files have 10000 patterns\n",
    "    \n",
    "A2_ring_merged=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-ring/A2-ring-merged.txt', sep='\\t', header=None)\n",
    "A2_ring_separable=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-ring/A2-ring-separable.txt', sep='\\t', header=None)\n",
    "A2_ring_test=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-ring/A2-ring-test.txt', sep='\\t', header=None)\n",
    "\n",
    "df_A2_ring_merged=pd.DataFrame(A2_ring_merged)\n",
    "df_A2_ring_separable=pd.DataFrame(A2_ring_separable)\n",
    "df_A2_ring_test=pd.DataFrame(A2_ring_test)\n",
    "\n",
    "# We plot the two input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second dataset: File: A2-bank.txt\n",
    "    # Data: bank-additional.csv (4119 patterns) or bank-additional-full.csv (41188 patterns), we choose one of them (the first is a subset of the second)\n",
    "    # Training: select the first 80% patterns for training\n",
    "    # Test: select the last 20% patterns for test\n",
    "    # Features: 20 features, most of them categorical, you will have to properly represent them as numerical data before training\n",
    "    # Input features: features that refer to the bank client, last contact in the current campaign, other attributes, and social and economic context attributes\n",
    "    # Prediction feature: the last one (yes/no), which corresponds to whether the client has subscribed a term deposit or not\n",
    "    # Observation: missing information is tagged as “unknown”\n",
    "\n",
    "bank_additional=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-bank/bank-additional.csv', sep=';', header=None)\n",
    "#bank_additional_full=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-bank/bank-additional-full.csv', sep=';', header=None)\n",
    "#bank_additional_names= pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/A2-bank/bank-additional-names.txt', sep=\"\\t\", header=None)\n",
    "\n",
    "df_bank_additional=pd.DataFrame(bank_additional)\n",
    "#df_bank_additional_full=pd.DataFrame(bank_additional_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third dataset: from \"https://www.kaggle.com/datasets/fatemehmehrparvar/liver-disorders?resource=download\"\n",
    "    # At least 6 features, one of them used for classification\n",
    "    # he classification feature can be binary or multivariate\n",
    "    # At least 400 patterns\n",
    "    # Select randomly 80% of the patterns for training and validation, and the remaining 20% for test; it is important to shuffle the original data, to destroy any kind of sorting it could have\n",
    "\n",
    "# Indian liver patient dataset [584 rows x 11 columns]\n",
    "liver_Disorder=pd.read_csv('C:/Users/Gari/Desktop/Assignments_NEC/A2/Indian Liver Patient Dataset (ILPD).csv', sep=',', header=None)\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "df_liver_Disorder=pd.DataFrame(liver_Disorder)\n",
    "\n",
    "#We drop the header\n",
    "# Drop the first row\n",
    "df_liver_Disorder = df_liver_Disorder.drop(df_liver_Disorder.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will do the data preprocessing to later do the data splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values, we check for and handle any missing values in our datasets\n",
    "# Categorical values, if there are categorical variables, we encode them appropriately\n",
    "# Outliers, we identify and handle the outliers in the data\n",
    "# Normalization, in case is needed\n",
    "\n",
    "# Data Preprocessing for Dataset 1 and 2\n",
    "# - Normalize input and output variables\n",
    "# - No need to preprocess (datasets already cleaned)\n",
    "\n",
    "# Data Preprocessing for Dataset 3\n",
    "# - Link to the source webpage to the documentation: \"\"https://www.kaggle.com/datasets/fatemehmehrparvar/liver-disorders?resource=download\"\n",
    "# - Check for missing values, represent categorical values, look for outliers\n",
    "# - Normalize input/output variables if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-ring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2-ring\n",
    "# We normalize the data that has been already splitted\n",
    "X_A2_ring_separable = df_A2_ring_separable.iloc[:, :-1]  # Features separable (all columns except the last one)\n",
    "y_A2_ring_separable = df_A2_ring_separable.iloc[:, -1]  # Target variable\n",
    "\n",
    "X_A2_ring_merged = df_A2_ring_merged.iloc[:, :-1]  # Features merged\n",
    "y_A2_ring_merged = df_A2_ring_merged.iloc[:, -1]  # Target variable\n",
    "\n",
    "X_A2_ring_test = df_A2_ring_test.iloc[:, :-1]  # Features\n",
    "y_A2_ring_test = df_A2_ring_test.iloc[:, -1]  # Target variable\n",
    "\n",
    "scaler_ring = MinMaxScaler()\n",
    "X_train_ring_separable = scaler_ring.fit_transform(X_A2_ring_separable) # Training set 1\n",
    "# Reshape the array to a 2D shape (required by MinMaxScaler)\n",
    "y_train_ring_separable = scaler_ring.fit_transform(y_A2_ring_separable.values.reshape(-1, 1))\n",
    "\n",
    "X_train_ring_merged = scaler_ring.fit_transform(X_A2_ring_merged) # Trainig set 2\n",
    "y_train_ring_merged = scaler_ring.fit_transform(y_A2_ring_merged.values.reshape(-1, 1))\n",
    "\n",
    "X_test_ring_normalized = scaler_ring.fit_transform(X_A2_ring_test) # Test\n",
    "y_test_ring_normalized = scaler_ring.fit_transform(y_A2_ring_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-bank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2-bank\n",
    "\n",
    "# Before normalizing the second dataset, it needs to be treated.\n",
    "# We have to treat the categorical data and the \"unknown\" values.\n",
    "\n",
    "# Treatment of the categorical data and the \"unknown\" values\n",
    "# Replace \"unknown\" values with NaN\n",
    "df_bank_additional.replace(\"unknown\", np.nan, inplace=True)\n",
    "\n",
    "# Handling missing values\n",
    "df_bank_additional.fillna(df_bank_additional.mode().iloc[0], inplace=True)\n",
    "\n",
    "# Extract the column names from the first row\n",
    "df_bank_additional.columns = df_bank_additional.iloc[0]\n",
    "df_bank_additional = df_bank_additional[1:]\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = df_bank_additional.select_dtypes(include=\"object\").columns\n",
    "\n",
    "for column in categorical_columns:\n",
    "    df_bank_additional[column] = label_encoder.fit_transform(df_bank_additional[column])\n",
    "\n",
    "# Separate the target variable\n",
    "X_bank_additional = df_bank_additional.drop(\"y\", axis=1)  # Features\n",
    "y_bank_additional = df_bank_additional[\"y\"]  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2-bank\n",
    "# Now, we normalize the data\n",
    "scaler_bank = MinMaxScaler()\n",
    "X_train_bank_additional = scaler_bank.fit_transform(X_bank_additional) # bank additional\n",
    "# Reshape the array to a 2D shape (required by MinMaxScaler)\n",
    "y_train_bank_additional = scaler_bank.fit_transform(y_bank_additional.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2-bank\n",
    "# Split the data into validation-training and testing sets\n",
    "# Extract the first 80% for training\n",
    "# Extract the remaining 20% for testing\n",
    "# Splitting A2-bank dataset\n",
    "X_train_bank, X_test_bank, y_train_bank, y_test_bank = train_test_split(\n",
    "    X_train_bank_additional, y_train_bank_additional, test_size=0.20, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liver disorder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liver disorder\n",
    "# We check if this dataset have missing values:\n",
    "missing_values_count = df_liver_Disorder.isnull().sum().sum()\n",
    "print(f\"Number of missing values in Liver disorder dataset: {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert the categorical data into numerical\n",
    "# Observing the dataset, there is a column with categorical data, which is the \"Gender\" with the name 1\n",
    "gender_mapping = {'Female': 0, 'Male': 1}\n",
    "df_liver_Disorder[1] = df_liver_Disorder[1].replace(gender_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We handle missing values using median imputation\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_liver_Disorder_imputed = pd.DataFrame(imputer.fit_transform(df_liver_Disorder), columns=df_liver_Disorder.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = df_liver_Disorder_imputed.isnull().sum().sum()\n",
    "print(f\"Number of missing values in Liver disorder dataset: {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and handle outliers using IQR method\n",
    "def handle_outliers_iqr(data, threshold=1.5):\n",
    "    data_copy = data.copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "    Q1 = data_copy.quantile(0.25)\n",
    "    Q3 = data_copy.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "    data_copy[(data_copy < lower_bound) | (data_copy > upper_bound)] = np.nan\n",
    "\n",
    "    # Handle missing values using median imputation\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    data_imputed = imputer.fit_transform(data_copy)\n",
    "    \n",
    "    # Convert back to DataFrame with original column names\n",
    "    data_imputed = pd.DataFrame(data_imputed, columns=data.columns)\n",
    "\n",
    "    return data_imputed\n",
    "\n",
    "# Handle outliers in all feature variables (columns) of df_liver_Disorder\n",
    "df_liver_Disorder_no_outliers = handle_outliers_iqr(df_liver_Disorder_imputed)\n",
    "\n",
    "# Shuffle\n",
    "df_liver_Disorder_shuffled = df_liver_Disorder_no_outliers.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = df_liver_Disorder_shuffled.isnull().sum().sum()\n",
    "print(f\"Number of missing values in Liver disorder dataset: {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_liver_Disorder = df_liver_Disorder_shuffled.iloc[:, :-1]\n",
    "y_liver_Disorder = df_liver_Disorder_shuffled.iloc[:, -1]\n",
    "\n",
    "# Normalize input variables\n",
    "scaler_liver_Disorder = MinMaxScaler()\n",
    "X_liver_Disorder_normalized_no_outliers = scaler_liver_Disorder.fit_transform(X_liver_Disorder)\n",
    "y_liver_Disorder_normalized_no_outliers = scaler_liver_Disorder.fit_transform(y_liver_Disorder.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third dataset, Liver disorder\n",
    "# Split the data into validation-training and testing sets\n",
    "# Extract the first 80% for training\n",
    "# Extract the remaining 20% for testing\n",
    "# Splitting liver_Disorder dataset\n",
    "X_train_wineQuality, X_test_wineQuality, y_train_wineQuality, y_test_wineQuality = train_test_split(\n",
    "    X_liver_Disorder_normalized_no_outliers,\n",
    "    y_liver_Disorder_normalized_no_outliers,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform supervised training of 3 classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM (support vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of SVM: kernel, and parameters\n",
    "def evaluate_svm(X_train, y_train, X_test, y_test, kernel, C):\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    # Create an SVM classifier with the desired parameters\n",
    "    svm_classifier = SVC(kernel=kernel, C=C)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(svm_classifier, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "    expected_error = 1 - np.mean(cv_scores)  # Expected classification error\n",
    "    \n",
    "    # Train the SVM classifier on the entire training set\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the classification error on the test set\n",
    "    test_error = 1 - accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return expected_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BP (back propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class CustomKerasClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.01, momentum=0.0, activation='relu', epochs=100, batch_size=32, verbose=1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.activation = activation\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Define model architecture\n",
    "        self.model = Sequential([\n",
    "            Dense(32, activation=self.activation),\n",
    "            Dense(10, activation=self.activation),\n",
    "            Dense(5, activation=self.activation),\n",
    "            Dense(1)\n",
    "        ])\n",
    "\n",
    "        # Compile model\n",
    "        self.model.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "        # Fit model\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.model.predict(X) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of BP: architecture of the network, learning rate and momentum, activation function, and number of epochs\n",
    "\n",
    "def evaluate_bp(X_train, y_train, X_test, y_test, learning_rate, momentum, activation, epochs):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    def create_model():\n",
    "        model = Sequential([\n",
    "            Dense(32, activation=activation),\n",
    "            Dense(10, activation=activation),\n",
    "            Dense(5, activation=activation),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    model = CustomKerasClassifier(epochs=epochs, \n",
    "                                  batch_size=32, \n",
    "                                  verbose=0,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  momentum=momentum,\n",
    "                                  activation=activation)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    expected_error = 1 - np.mean(cv_scores)  # Expected classification error\n",
    "    \n",
    "    # Fit the model to the entire training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the classification error on the test set\n",
    "    test_error = 1 - accuracy_score(y_test, y_pred.round())\n",
    "    \n",
    "    return expected_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLR (multi-linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mlr(X_train, y_train, X_test, y_test, C, solver):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create a logistic regression classifier with the current parameters\n",
    "    logistic_regression = LogisticRegression(C=C, solver=solver)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(logistic_regression, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "    expected_error = 1 - np.mean(cv_scores)  # Expected classification error\n",
    "    \n",
    "    # Train the logistic regression classifier on the entire training set\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = logistic_regression.predict(X_test)\n",
    "    \n",
    "    # Calculate the classification error on the test set\n",
    "    test_error = 1 - accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return expected_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic process to find the best parameters (kernel, C) for the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_svm(X_train, y_train, X_test, y_test):\n",
    "    # Set initial parameters\n",
    "    C_values = [0.1, 1, 10, 100, 1000]  # Values for C\n",
    "    kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']  # Values for kernel\n",
    "    best_test_error = float('inf')\n",
    "    best_expected_error = float('inf')\n",
    "    best_params = {'kernel': None, 'C': None}\n",
    "\n",
    "    # Tune C\n",
    "    for C in C_values:\n",
    "        # Calculate the classification error\n",
    "        expected_error, test_error = evaluate_svm(X_train, y_train, X_test, y_test, kernel=kernel_values[0], C=C)\n",
    "        \n",
    "        # Update best error and parameters if current error is lower\n",
    "        if test_error < best_test_error:\n",
    "            best_test_error = test_error\n",
    "            best_expected_error = expected_error\n",
    "            best_params['C'] = C\n",
    "        \n",
    "    best_test_error = float('inf')  # Initialize with a large value\n",
    "    # Tune kernel\n",
    "    for kernel in kernel_values:\n",
    "        expected_error, test_error = evaluate_svm(X_train, y_train, X_test, y_test, kernel=kernel, C=best_params['C'])\n",
    "        \n",
    "        # Update best error and parameters if current error is lower\n",
    "        if test_error < best_test_error:\n",
    "            best_test_error = test_error\n",
    "            best_expected_error = expected_error\n",
    "            best_params['kernel'] = kernel\n",
    "    \n",
    "    return best_params, best_expected_error, best_test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic process to find the best parameters (learning_rate, momentum, activation, epochs) for the BP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_backpropagation(X_train, y_train, X_test, y_test):\n",
    "    # Set initial parameters\n",
    "    learning_rates = [0.2, 0.15, 0.1, 0.015, 0.01]  # Values for learning rate\n",
    "    momentums = [0.0, 0.3, 0.6, 0.9]  # Values for momentum\n",
    "    activations = ['sigmoid', 'relu', 'linear', 'tanh']  # Values for activation\n",
    "    epochs_values = [50, 100, 200, 500, 1000] # Number of epochs\n",
    "\n",
    "    best_error  = float('inf')  # Initialize with a large value\n",
    "    best_expected_error = float('inf')\n",
    "    best_hyperparameters = {'learning_rate': None, 'momentum': None, 'activation': None, 'epochs': None}\n",
    "\n",
    "    # Tune learning rate\n",
    "    for learning_rate in learning_rates:\n",
    "        expected_error, test_error = evaluate_bp(X_train, y_train, X_test, y_test, learning_rate, momentums[0], activations[0], epochs_values[0])\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_expected_error = expected_error\n",
    "            best_hyperparameters['learning_rate'] = learning_rate\n",
    "\n",
    "    best_error = float('inf')  # Initialize with a large value\n",
    "    # Tune momentum\n",
    "    for momentum in momentums:\n",
    "        expected_error, test_error = evaluate_bp(X_train, y_train, X_test, y_test, best_hyperparameters['learning_rate'], momentum, activations[0], epochs_values[0])\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_expected_error = expected_error\n",
    "            best_hyperparameters['momentum'] = momentum\n",
    "\n",
    "    best_error = float('inf')  # Initialize with a large value\n",
    "    # Tune activation\n",
    "    for activation in activations:\n",
    "        expected_error, test_error = evaluate_bp(X_train, y_train, X_test, y_test, best_hyperparameters['learning_rate'], best_hyperparameters['momentum'], activation, epochs_values[0])\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_expected_error = expected_error\n",
    "            best_hyperparameters['activation'] = activation\n",
    "\n",
    "    best_error = float('inf')  # Initialize with a large value\n",
    "    # Tune epochs\n",
    "    for epochs in epochs_values:\n",
    "        expected_error, test_error = evaluate_bp(X_train, y_train, X_test, y_test, best_hyperparameters['learning_rate'], best_hyperparameters['momentum'], best_hyperparameters['activation'], epochs)\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_expected_error = expected_error\n",
    "            best_hyperparameters['epochs'] = epochs\n",
    "\n",
    "    return best_hyperparameters, best_expected_error, best_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic process to find the best parameters (C, solver) for the MLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    import warnings\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import numpy as np\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Set initial parameters\n",
    "    C_values = [0.01, 0.1, 1, 10, 100]  # Values for regularization parameter C\n",
    "    solver_values = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']  # Values for the optimization algorithm\n",
    "\n",
    "    best_error = float('inf')  # Initialize with a large value\n",
    "    best_expected_error = float('inf')\n",
    "    best_params = {'C': None, 'solver': None}\n",
    "\n",
    "    # Tune C\n",
    "    for C in C_values:\n",
    "        # Calculate the classification error\n",
    "        expected_error, test_error = evaluate_mlr(X_train, y_train, X_test, y_test, C=C, solver=solver_values[0])\n",
    "\n",
    "        # Update best error and C if current error is lower\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_expected_error = expected_error\n",
    "            best_params['C'] = C\n",
    "\n",
    "    best_error = float('inf')  # Initialize with a large value\n",
    "    \n",
    "    # Tune solver\n",
    "    for solver in solver_values:\n",
    "        expected_error, test_error = evaluate_mlr(X_train, y_train, X_test, y_test, C=best_params['C'], solver=solver)\n",
    "\n",
    "        # Update best error and solver if current error is lower\n",
    "        if test_error < best_error:\n",
    "            best_error = test_error\n",
    "            best_expected_error = expected_error\n",
    "            best_params['solver'] = solver\n",
    "\n",
    "    return best_params, best_expected_error, best_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the before functions to finde the best parameters for our datasets for the three models (SVM, BP, MLR):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 1: A2-ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_ring_merged\n",
    "y_train = y_train_ring_merged\n",
    "X_test = X_test_ring_normalized\n",
    "y_test = y_test_ring_normalized\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#SVM\n",
    "best_params_svm, best_expected_error_svm, best_error_svm = tune_svm(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for SVM:\", best_params_svm)\n",
    "print(\"Expected classification error obtained from cross-validation:\", best_expected_error_svm)\n",
    "print(\"Best classification error on the test set for SVM:\", best_error_svm)\n",
    "\n",
    "# BP\n",
    "best_params_bp, best_expected_error_bp, best_error_bp = tune_backpropagation(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for BP:\", best_params_bp)\n",
    "print(\"Expected classification error obtained from cross-validation:\", best_expected_error_bp)\n",
    "print(\"Best classification error on the test set for BP:\", best_error_bp)\n",
    "\n",
    "#MLR\n",
    "best_params_mlr, best_expected_error_mlr, best_error_mlr = tune_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for MLR:\", best_params_mlr)\n",
    "print(\"Expected classification error obtained from cross-validation:\", best_expected_error_mlr)\n",
    "print(\"Best classification error on the test set for MLR:\", best_error_mlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 2: A2-bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_bank\n",
    "y_train = y_train_bank\n",
    "X_test = X_test_bank\n",
    "y_test = y_test_bank\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#SVM\n",
    "best_params_svm, best_expected_error_svm, best_error_svm = tune_svm(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for SVM:\", best_params_svm)\n",
    "print(\"Expected classification error obtained from cross-validation:\", best_expected_error_svm)\n",
    "print(\"Best classification error on the test set for SVM:\", best_error_svm)\n",
    "\n",
    "# BP\n",
    "best_params_bp, best_expected_error_bp, best_error_bp = tune_backpropagation(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for BP:\", best_params_bp)\n",
    "print(\"Expected classification error obtained from cross-validation:\", best_expected_error_bp)\n",
    "print(\"Best classification error on the test set for BP:\", best_error_bp)\n",
    "\n",
    "#MLR\n",
    "best_params_mlr, best_expected_error_mlr, best_error_mlr = tune_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for MLR:\", best_params_mlr)\n",
    "print(\"Expected classification error obtained from cross-validation:\", best_expected_error_mlr)\n",
    "print(\"Best classification error on the test set for MLR:\", best_error_mlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 3: liver disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_wineQuality\n",
    "y_train = y_train_wineQuality\n",
    "X_test = X_test_wineQuality\n",
    "y_test = y_test_wineQuality\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#SVM\n",
    "best_params_svm, best_expected_error_svm, best_error_svm = tune_svm(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for SVM:\", best_params_svm)\n",
    "print(\"Expected classification error obtained from cross-validation:\", best_expected_error_svm)\n",
    "print(\"Best classification error on the test set for SVM:\", best_error_svm)\n",
    "\n",
    "# BP\n",
    "best_params_bp, best_expected_error_bp, best_error_bp = tune_backpropagation(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for BP:\", best_params_bp)\n",
    "print(\"Expected classification error obtained from cross-validation:\", best_expected_error_bp)\n",
    "print(\"Best classification error on the test set for BP:\", best_error_bp)\n",
    "\n",
    "#MLR\n",
    "best_params_mlr, best_expected_error_mlr, best_error_mlr = tune_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "print(\"Best parameters for MLR:\", best_params_mlr)\n",
    "print(\"Expected classification error obtained from cross-validation:\", best_expected_error_mlr)\n",
    "print(\"Best classification error on the test set for MLR:\", best_error_mlr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
